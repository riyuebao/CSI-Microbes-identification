from os.path import join, basename
import pandas as pd
from snakemake.utils import min_version
##### set minimum snakemake version #####
min_version("5.1.2")
##### load config and sample sheets #####
configfile: join("config", "PathSeq-config.yaml")
#validate(config, schema="schemas/config.schema.yaml")

patients = pd.read_csv(config["patients"], sep="\t").set_index("patient", drop=False)
# validate(samples, schema="schemas/samples.schema.yaml")

samples = pd.read_csv(config["samples"], dtype=str, sep="\t").set_index(["patient", "sample"], drop=False)


DROPSEQ2_3_URL = "https://github.com/broadinstitute/Drop-seq/releases/download/v2.3.0/Drop-seq_tools-2.3.0.zip"
# Directories
FASTQ_DIR = "FASTQ"

# Input Files
SRA_FASTQ1_FILE = join(FASTQ_DIR, "{run}_1.fastq")
SRA_FASTQ2_FILE = join(FASTQ_DIR, "{run}_2.fastq")
SAMPLE_FASTQ1_FILE = join("output", "{patient}-{sample}", "{sample}_1.fastq")
SAMPLE_FASTQ2_FILE = join("output", "{patient}-{sample}", "{sample}_2.fastq")
UNALIGNED_BAM = join("output", "{patient}-{sample}", "unaligned.bam")
UNALIGNED_TAGGED_CELL_BAM = join("output", "{patient}-{sample}", "unaligned_tagged_Cell.bam")
UNALIGNED_TAGGED_CELL_SUMMARY = join("output", "{patient}-{sample}", "unaligned_tagged_Cell.bam_summary.txt")
# drop-seq script files
DROP_SEQ_DIR = "Drop-seq_tools-2.3.0"
TagBamWithReadSequenceExtended = join(DROP_SEQ_DIR, "TagBamWithReadSequenceExtended")
# instructions taken from https://github.com/broadinstitute/Drop-seq/blob/master/doc/Drop-seq_Alignment_Cookbook.pdf

rule all:
    input:
        expand(SAMPLE_FASTQ1_FILE, patient="Pt0", sample="GSM2486334")

rule download_DropSeq_tools:
    params:
        DROPSEQ2_3_URL
    output:
        temp("temp.zip"),
        TagBamWithReadSequenceExtended
    shell:
        "wget {params} -O temp.zip && unzip temp.zip"

rule add_cell_barcode:
    input:
        UNALIGNED_BAM,
        TagBamWithReadSequenceExtended
    output:
        UNALIGNED_TAGGED_CELL_BAM,
        UNALIGNED_TAGGED_CELL_SUMMARY
    shell:
        "{TagBamWithReadSequenceExtended} INPUT={input[0]} "
        "OUTPUT={output[0]} SUMMARY={output[1]} BASE_RANGE=1-12 "
        "BASE_QUALITY=20 BARCODED_READ=1 DISCARD_READ=False "
        "TAG_NAME=XC NUM_BASES_BELOW_QUALITY=1"

rule convert_fastq_to_bam:
    input:
        SAMPLE_FASTQ1_FILE,
        SAMPLE_FASTQ2_FILE
    output:
        UNALIGNED_BAM
    shell:
        "module load picard && "
        "java -jar $PICARDJARPATH/picard.jar FastqToSam "
        "F1={input[0]} F2={input[1]} "
        "O={output} "
        "SM={wildcards.sample} "
        "RG={wildcards.sample} "

def get_fqs_same_sample(wildcards):
    runs = samples.at[(wildcards.patient, wildcards.sample), "Run"]
    return {
        "FQ1": expand(SRA_FASTQ1_FILE, run=runs),
        "FQ2": expand(SRA_FASTQ2_FILE, run=runs),
    }

rule combine_FASTQs:
    input:
        unpack(get_fqs_same_sample)
    output:
        fq1 = SAMPLE_FASTQ1_FILE,
        fq2 = SAMPLE_FASTQ2_FILE
    run:
        for fq1 in input.FQ1:
            shell("cat {fq1} >> {output[0]}")
        for fq2 in input.FQ2:
            shell("cat {fq2} >> {output[1]}")


rule download_FASTQ_from_SRA:
    params:
        FASTQ_DIR
    output:
        temp(SRA_FASTQ1_FILE),
        temp(SRA_FASTQ2_FILE)
    shell:
        "module load sratoolkit && "
        "fasterq-dump -O {params} -t /lscratch/$SLURM_JOBID "
        "--include-technical --split-files {wildcards.run}"
