from os.path import join
import pandas as pd
from snakemake.utils import min_version
##### set minimum snakemake version #####
min_version("5.1.2")

##### load config and sample sheets #####
configfile: "config/PathSeq-config.yaml"

# URLs
LT2_genome_URL = "ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/006/945/GCF_000006945.2_ASM694v2/GCF_000006945.2_ASM694v2_genomic.fna.gz"
D23580_genome_URL = "ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/900/538/085/GCF_900538085.1_D23580_liv/GCF_900538085.1_D23580_liv_genomic.fna.gz"
LT2_GTF_URL = "ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/006/945/GCF_000006945.2_ASM694v2/GCF_000006945.2_ASM694v2_genomic.gtf.gz"
D23580_GTF_URL = "ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/900/538/085/GCF_900538085.1_D23580_liv/GCF_900538085.1_D23580_liv_genomic.gtf.gz"

# metadata
patients = pd.read_csv(config["patients"], sep="\t").set_index("patient", drop=False)
samples = pd.read_csv(config["samples"], dtype=str, sep="\t").set_index(["patient", "sample"], drop=False)
cells = pd.read_csv(config["units"], dtype=str, sep="\t").set_index(["patient", "sample", "cell"], drop=False)

wildcard_constraints:
    patient="|".join(cells["patient"].unique()),
    sample="|".join(cells["sample"].unique()),
    plate="|".join(cells["plate"].unique()),
    cell="|".join(cells["cell"].unique()),
    genome="LT2|D23580"

# directories
FASTQ_DIR = join("FASTQ")
RAW_FASTQ_DIR = join(FASTQ_DIR, "raw")

# Intermediate Files for cells
SRA_FASTQ1_FILE = join(RAW_FASTQ_DIR,  "{run}_1.fastq")
SRA_FASTQ2_FILE = join(RAW_FASTQ_DIR, "{run}_2.fastq")
FASTQ1_FILE = join(RAW_FASTQ_DIR,  "{patient}-{sample}-{cell}_1.fastq.gz")
FASTQ2_FILE = join(RAW_FASTQ_DIR, "{patient}-{sample}-{cell}_2.fastq.gz")

# PathSeq Output Files
PathSeq_BAM_File = join("output", "PathSeq", "{patient}-{sample}-{plate}", "pathseq.bam")
PathSeq_Cell_Score_File = join("output", "PathSeq", "{patient}-{sample}-{plate}-{cell}", "pathseq.txt")

# Intermediate Files for SRPRISM
GENOME_GTF = join("raw", "{genome}.gtf")
BED_FILTER_FILE=join("raw", "{genome}_{filter}.bed")

# SRPRISM Output Files
SRPRISM_INPUT_FQ1 = join("output", "star", "{patient}-{sample}-{plate}-{cell}", "unaligned_1.fq")
SRPRISM_INPUT_FQ2 = join("output", "star", "{patient}-{sample}-{plate}-{cell}", "unaligned_2.fq")
SRPRISM_COUNT_FILE = join("output", "SRPRISM", "{patient}", "{sample}", "read_counts.tsv")
SRPRISM_FILTER_COUNT_FILE = join("output", "SRPRISM", "{patient}", "{sample}", "{filter}_read_counts.tsv")
#SRPRISM_rRNA_COUNT_FILE = join("output", "SRPRISM", "{patient}", "{sample}", "rRNA_read_counts.tsv")

SRPRISM_FILTER_BAM = join("output", "SRPRISM", "{patient}", "{sample}-{plate}-{cell}", "{genome}-paired.{filter}.primary.sorted.bam")
SRPRISM_NON_FILTER_BAM = join("output", "SRPRISM", "{patient}", "{sample}-{plate}-{cell}", "{genome}-paired.non.{filter}.primary.sorted.bam")
#SRPRISM_rRNA_BAM = join("output", "SRPRISM", "{patient}", "{sample}-{plate}-{cell}", "{genome}-paired.rRNA.primary.sorted.bam")
#SRPRISM_NON_rRNA_BAM = join("output", "SRPRISM", "{patient}", "{sample}-{plate}-{cell}", "{genome}-paired.nonrRNA.primary.sorted.bam")


# include rules
include: "../RNA-snakemake-rules/rules/ERCC92.smk"
include: "../RNA-snakemake-rules/rules/genome.smk"
include: "../RNA-snakemake-rules/rules/trim.smk"
include: "../RNA-snakemake-rules/rules/STARsolo_SmartSeq.smk"
include: "../RNA-snakemake-rules/rules/SRPRISM-paired.smk"
include: "../pathogen-discovery-rules/rules/filter-host-reads.smk"
include: "../pathogen-discovery-rules/rules/PathSeq-host-filter-single.smk"
include: "../pathogen-discovery-rules/rules/CAMMiQ.smk"

localrules: filter_reads

plates = cells[["patient", "sample", "plate"]].drop_duplicates()

cells = cells.loc[cells.infection.isin(["LT2", "D23580"])]
#D23580_cells = cells.loc[cells.infection == "D23580"]
# LT2_cells = LT2_cells.iloc[0:10]


rule all:
    input:
        expand(SRPRISM_COUNT_FILE, patient="Pt0", sample="S0"),
        expand(SRPRISM_FILTER_COUNT_FILE, patient="Pt0", sample="S0", filter=["rRNA", "16S"])


# rules for manipulating SPRISM bam files
rule filter_reads:
    input:
        SRPRISM_PROPER_PAIRED_PRIMARY_SORTED_BAM,
        SRPRISM_PROPER_PAIRED_PRIMARY_SORTED_BAI,
        BED_FILTER_FILE
    output:
        SRPRISM_FILTER_BAM,
        SRPRISM_NON_FILTER_BAM
    shell:
        "module load samtools && "
        "samtools view -h -b -L {input[2]} -U {output[1]} {input[0]} > {output[0]}"

# count the reads and combine
rule count_total_reads:
    params:
        cells=cells["cell"]
    conda:
        "../envs/pysam-env.yaml"
    input:
        expand(SRPRISM_PROPER_PAIRED_PRIMARY_BAM,  zip, patient=cells["patient"],
               sample=cells["sample"], plate=cells["plate"], cell=cells["cell"],
               genome=cells["infection"])
    output:
        SRPRISM_COUNT_FILE
    script:
        "src/count_nreads.py"

def get_filtered_bam_files(wildcards):
    return expand(SRPRISM_FILTER_BAM,  zip, patient=cells["patient"],
           sample=cells["sample"], plate=cells["plate"], cell=cells["cell"],
           genome=cells["infection"], filter=[wildcards.filter]*cells.shape[0])

rule count_filtered_reads:
    params:
        cells=cells["cell"]
    conda:
        "../envs/pysam-env.yaml"
    input:
        get_filtered_bam_files
    output:
        SRPRISM_FILTER_COUNT_FILE
    script:
        "src/count_nreads.py"

# rule count_rRNA_reads:
#     params:
#         cells=cells["cell"]
#     conda:
#         "../envs/pysam-env.yaml"
#     input:
#         expand(SRPRISM_rRNA_BAM,  zip, patient=cells["patient"],
#                sample=cells["sample"], plate=cells["plate"], cell=cells["cell"],
#                genome=cells["infection"])
#     output:
#         SRPRISM_rRNA_COUNT_FILE
#     script:
#         "src/count_nreads.py"

rule extract_filter_BED:
    wildcard_constraints:
        filter="rRNA|16S"
    conda:
        "../envs/pysam-env.yaml"
    input:
        GENOME_GTF
    output:
        BED_FILTER_FILE,
    script:
        "src/extract_rRNA_coordinates.py"

# rule download_combine_subspe_genomes:
#     input:
#         join("data", "microbe_subset_assembly_summary.txt")
#     output:
#         join("data", "microbev1.fa")
#     run:
#         df = pd.read_csv(input[0], sep="\t")
#         shell("touch {output}")
#         for index, row in df.iterrows():
#             url = row["url"]
#             shell("wget -O - {url} | gunzip -c >> {output}")

# Rules and functions for downloading Salmonella files
rule download_D23580_genome:
    wildcard_constraints:
        genome="D23580"
    params:
        D23580_genome_URL
    output:
        GENOME_FA
    shell:
        "wget -O - {params[0]} | gunzip -c > {output}"

rule download_LT2_genome:
    wildcard_constraints:
        genome="LT2"
    params:
        LT2_genome_URL
    output:
        GENOME_FA
    shell:
        "wget -O - {params[0]} | gunzip -c > {output}"

rule download_D23580_GTF:
    wildcard_constraints:
        genome="D23580"
    params:
        D23580_GTF_URL
    output:
        GENOME_GTF
    shell:
        "wget -O - {params[0]} | gunzip -c > {output}"

rule download_LT2_GTF:
    wildcard_constraints:
        genome="LT2"
    params:
        LT2_GTF_URL
    output:
        GENOME_GTF
    shell:
        "wget -O - {params[0]} | gunzip -c > {output}"

# Rules and functions for downloading sequencing data

def get_SRA_fq_files(wildcards):
    run = cells.loc[(wildcards.patient, wildcards.sample, wildcards.cell), "Run"]
    return {
        "FQ1": SRA_FASTQ1_FILE.format(run=run),
        "FQ2": SRA_FASTQ2_FILE.format(run=run),
    }

rule compress_FASTQ_File:
    group:
        "FASTQ"
    input:
        unpack(get_SRA_fq_files)
    output:
        FASTQ1_FILE,
        FASTQ2_FILE
    shell:
        "gzip -vc {input[FQ1]} > {output[0]} && "
        "gzip -vc {input[FQ2]} > {output[1]}"

rule download_FASTQ_from_SRA:
    group:
        "FASTQ"
    params:
        RAW_FASTQ_DIR
    output:
        temp(SRA_FASTQ1_FILE),
        temp(SRA_FASTQ2_FILE)
    shell:
        "module load sratoolkit && "
        "fasterq-dump -O {params} -t /lscratch/$SLURM_JOBID "
        "--split-files {wildcards.run}"
