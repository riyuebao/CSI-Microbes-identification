from os.path import join, basename
import math
import pandas as pd
import numpy as np
from snakemake.utils import min_version
##### set minimum snakemake version #####
min_version("5.1.2")

wildcard_constraints:
    patient="MGH42|MGH43|MGH44|MGH45|MGH56|MGH57|MGH61|MGH64|MGH103|MGH107"

##### load config and sample sheets #####
configfile: join("config", "PathSeq-config.yaml")
patients = pd.read_csv(config["patients"], sep="\t").set_index("patient", drop=False)
samples = pd.read_csv(config["samples"], dtype=str, sep="\t").set_index(["patient", "sample"], drop=False)
samples.index = samples.index.set_levels([i.astype(str) for i in samples.index.levels])  # enforce str in index

# directories
FASTQ_DIR = join("FASTQ", "raw")

# Intermediate Files
RAW_FASTQ1_FILE = "/data/Robinson-SB/Venteicher2017-fastq-files/{sample}_R1.fastq.gz"
RAW_FASTQ2_FILE = "/data/Robinson-SB/Venteicher2017-fastq-files/{sample}_R2.fastq.gz"
FASTQ1_FILE = join(FASTQ_DIR,  "{patient}-{sample}_1.fastq.gz")
FASTQ2_FILE = join(FASTQ_DIR, "{patient}-{sample}_2.fastq.gz")

# Output Files
PAIRED_FILTERED_BAM = join("output", "PathSeq", "{patient}-{sample}", "filtered-paired.bam")
UNPAIRED_FILTERED_BAM = join("output", "PathSeq", "{patient}-{sample}", "filtered-unpaired.bam")
PAIRED_ALIGNED_BAM = join("output", "PathSeq", "{patient}-{sample}", "aligned-paired.bam")
UNPAIRED_ALIGNED_BAM = join("output", "PathSeq", "{patient}-{sample}", "aligned-unpaired.bam")

# include: "../../pathogen-discovery-rules/rules/kraken.smk"
samples = samples.iloc[0:10]
localrules: convert_FASTQ_to_BAM

rule all:
    input:
        expand(join("output", "PathSeq", "v1", "{patient}-{sample}", "pathseq.txt"), sample=samples["sample"], patient=samples["patient"]),
        expand(join("output", "PathSeq", "v2", "{patient}-{sample}", "pathseq.txt"), sample=samples["sample"], patient=samples["patient"]),
        expand(join("output", "PathSeq", "v3", "{patient}-{sample}", "pathseq.txt"), sample=samples["sample"], patient=samples["patient"]),



rule PathSeqPipelineSpark:
    input:
        bam_file = config["PathSeq"]["bam_file"],
        host_bwa_image = config["PathSeq"]["host_img"],
        microbe_bwa_image = config["PathSeq"]["microbe_bwa_image"],
        microbe_fasta_file = config["PathSeq"]["microbe_fasta"],
        host_hss_file = config["PathSeq"]["host_bfi"],
        taxonomy_db = config["PathSeq"]["taxonomy_db"]
    output:
        pathseq_bam = join("output", "PathSeq", "v1", "{patient}-{sample}", "pathseq.bam"),
        pathseq_output = join("output", "PathSeq", "v1", "{patient}-{sample}", "pathseq.txt")
    shell:
        "mkdir /lscratch/$SLURM_JOBID/tmp && "
        "module load GATK/4.1.6.0 && "
        "gatk PathSeqPipelineSpark "
        "--input '{input.bam_file}' "
        "--filter-bwa-image '{input.host_bwa_image}' "
        "--kmer-file '{input.host_hss_file}' "
        "--microbe-fasta '{input.microbe_fasta_file}' "
        "--microbe-bwa-image '{input.microbe_bwa_image}' "
        "--taxonomy-file '{input.taxonomy_db}' "
        "--output '{output.pathseq_bam}' "
        "--scores-output '{output.pathseq_output}' "
        '--java-options "-Xmx48g -Xms48G -Djava.io.tmpdir=/lscratch/$SLURM_JOBID/tmp -XX:+UseG1GC -XX:ParallelGCThreads=8 -XX:ConcGCThreads=2" '
        '--spark-master local[4]'
        #+ config["params"]["PathSeq"]["pipeline"]

rule PathSeqPipelineSpark_lscratch4:
    input:
        bam_file = config["PathSeq"]["bam_file"],
        host_bwa_image = config["PathSeq"]["host_img"],
        microbe_bwa_image = config["PathSeq"]["microbe_bwa_image"],
        microbe_fasta_file = config["PathSeq"]["microbe_fasta"],
        host_hss_file = config["PathSeq"]["host_bfi"],
        taxonomy_db = config["PathSeq"]["taxonomy_db"]
    params:
        host_bwa_image = basename(config["PathSeq"]["host_img"]),
        microbe_bwa_image = basename(config["PathSeq"]["microbe_bwa_image"]),
        microbe_fasta_file = basename(config["PathSeq"]["microbe_fasta"]),
        host_hss_file = basename(config["PathSeq"]["host_bfi"]),
        taxonomy_db = basename(config["PathSeq"]["taxonomy_db"])
    output:
        pathseq_bam = join("output", "PathSeq", "v2", "{patient}-{sample}", "pathseq.bam"),
        pathseq_output = join("output", "PathSeq", "v2", "{patient}-{sample}", "pathseq.txt")
    shell:
        "startt=$(date +%s) && "
        "mkdir /lscratch/$SLURM_JOBID/tmp && "
        "cp /data/Robinson-SB/PathSeq-data/* /lscratch/$SLURM_JOBID && "
        "endt=$(date +%s) && "
        'printf "took %ss to cp files to lscratch\n" $((endt - startt)) && '
        "module load GATK/4.1.6.0 && "
        "gatk PathSeqPipelineSpark "
        "--input '{input.bam_file}' "
        "--filter-bwa-image /lscratch/$SLURM_JOBID/{params.host_bwa_image} "
        "--kmer-file /lscratch/$SLURM_JOBID/{params.host_hss_file} "
        "--microbe-fasta /lscratch/$SLURM_JOBID/{params.microbe_fasta_file} "
        "--microbe-bwa-image /lscratch/$SLURM_JOBID/{params.microbe_bwa_image} "
        "--taxonomy-file /lscratch/$SLURM_JOBID/{params.taxonomy_db} "
        "--output '{output.pathseq_bam}' "
        "--scores-output '{output.pathseq_output}' "
        '--java-options "-Xmx48g -Xms48G -Djava.io.tmpdir=/lscratch/$SLURM_JOBID/tmp -XX:+UseG1GC -XX:ParallelGCThreads=8 -XX:ConcGCThreads=2" '
        '--spark-master local[4]'

rule PathSeqPipelineSpark_lscratch8:
    input:
        bam_file = config["PathSeq"]["bam_file"],
        host_bwa_image = config["PathSeq"]["host_img"],
        microbe_bwa_image = config["PathSeq"]["microbe_bwa_image"],
        microbe_fasta_file = config["PathSeq"]["microbe_fasta"],
        host_hss_file = config["PathSeq"]["host_bfi"],
        taxonomy_db = config["PathSeq"]["taxonomy_db"]
    params:
        host_bwa_image = basename(config["PathSeq"]["host_img"]),
        microbe_bwa_image = basename(config["PathSeq"]["microbe_bwa_image"]),
        microbe_fasta_file = basename(config["PathSeq"]["microbe_fasta"]),
        host_hss_file = basename(config["PathSeq"]["host_bfi"]),
        taxonomy_db = basename(config["PathSeq"]["taxonomy_db"])
    output:
        pathseq_bam = join("output", "PathSeq", "v3", "{patient}-{sample}", "pathseq.bam"),
        pathseq_output = join("output", "PathSeq", "v3", "{patient}-{sample}", "pathseq.txt")
    shell:
        "startt=$(date +%s) && "
        "mkdir /lscratch/$SLURM_JOBID/tmp && "
        "cp /data/Robinson-SB/PathSeq-data/* /lscratch/$SLURM_JOBID && "
        "endt=$(date +%s) && "
        'printf "took %ss to cp files to lscratch\n" $((endt - startt)) && '
        "module load GATK/4.1.6.0 && "
        "gatk PathSeqPipelineSpark "
        "--input '{input.bam_file}' "
        "--filter-bwa-image /lscratch/$SLURM_JOBID/{params.host_bwa_image} "
        "--kmer-file /lscratch/$SLURM_JOBID/{params.host_hss_file} "
        "--microbe-fasta /lscratch/$SLURM_JOBID/{params.microbe_fasta_file} "
        "--microbe-bwa-image /lscratch/$SLURM_JOBID/{params.microbe_bwa_image} "
        "--taxonomy-file /lscratch/$SLURM_JOBID/{params.taxonomy_db} "
        "--output '{output.pathseq_bam}' "
        "--scores-output '{output.pathseq_output}' "
        '--java-options "-Xmx64g -Xms64G -Djava.io.tmpdir=/lscratch/$SLURM_JOBID/tmp -XX:+UseG1GC -XX:ParallelGCThreads=8 -XX:ConcGCThreads=2" '
        '--spark-master local[8]'





rule convert_FASTQ_to_BAM:
    input:
        fq1=RAW_FASTQ1_FILE,
        fq2=RAW_FASTQ2_FILE
    output:
        config["PathSeq"]["bam_file"]
    shell:
        "module load picard && "
        "java -Xmx8g -XX:ParallelGCThreads=5 -jar $PICARDJARPATH/picard.jar "
        "FastqToSam F1={input.fq1} F2={input.fq2} O={output} "
        "SM={wildcards.sample} RG={wildcards.sample} "
        "TMP_DIR=/lscratch/$SLURM_JOBID"

rule move_and_rename_FASTQ_File:
    input:
        RAW_FASTQ1_FILE,
        RAW_FASTQ2_FILE
    output:
        temp(FASTQ1_FILE),
        temp(FASTQ2_FILE)
    shell:
        "cp {input[0]} {output[0]} && "
        "cp {input[1]} {output[1]}"
