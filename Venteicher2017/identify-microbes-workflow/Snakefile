from os.path import join, basename
import math
import pandas as pd
import numpy as np
from snakemake.utils import min_version
##### set minimum snakemake version #####
min_version("5.1.2")

wildcard_constraints:
    patient="MGH42|MGH43|MGH44|MGH45|MGH56|MGH57|MGH61|MGH64|MGH103|MGH107"
patient = config["patient"]
plate = config["plate"]
##### load config and sample sheets #####
configfile: join("config", "PathSeq-config.yaml")
patients = pd.read_csv(config["patients"], sep="\t").set_index("patient", drop=False)
samples = pd.read_csv(config["samples"], dtype=str, sep="\t").set_index(["patient", "sample"], drop=False)
samples.index = samples.index.set_levels([i.astype(str) for i in samples.index.levels])  # enforce str in index
samples = samples.loc[samples.patient == patient]
samples = samples.loc[samples.plate == plate]
samples = samples.sample(frac=1, random_state=0)
nrows = min(30, samples.shape[0])
samples = samples.iloc[0:nrows]
# directories
FASTQ_DIR = join("FASTQ", "raw")

# Intermediate Files
RAW_FASTQ1_FILE = "/data/Robinson-SB/Venteicher2017-fastq-files/{sample}_R1.fastq.gz"
RAW_FASTQ2_FILE = "/data/Robinson-SB/Venteicher2017-fastq-files/{sample}_R2.fastq.gz"
FASTQ1_FILE = join(FASTQ_DIR,  "{patient}-{sample}_1.fastq.gz")
FASTQ2_FILE = join(FASTQ_DIR, "{patient}-{sample}_2.fastq.gz")

# Output Files
PAIRED_FILTERED_BAM = join("output", "PathSeq", "{patient}-{sample}", "filtered-paired.bam")
UNPAIRED_FILTERED_BAM = join("output", "PathSeq", "{patient}-{sample}", "filtered-unpaired.bam")
PAIRED_ALIGNED_BAM = join("output", "PathSeq", "{patient}-{sample}", "aligned-paired.bam")
UNPAIRED_ALIGNED_BAM = join("output", "PathSeq", "{patient}-{sample}", "aligned-unpaired.bam")

# include: "../../pathogen-discovery-rules/rules/kraken.smk"
# use parameters passed to subset the samples
# samples = samples.iloc[0:10]
# localrules: convert_FASTQ_to_BAM

rule all:
    input:
        expand(join("output", "PathSeq", "{patient}-{sample}", "pathseq.txt"), zip, sample=samples["sample"], patient=samples["patient"]),





rule PathSeqPipelineSpark_lscratch8:
    input:
        bam_file = expand(config["PathSeq"]["bam_file"], sample=samples["sample"], patient=samples["patient"]),
        host_bwa_image = config["PathSeq"]["host_img"],
        microbe_bwa_image = config["PathSeq"]["microbe_bwa_image"],
        microbe_fasta_file = config["PathSeq"]["microbe_fasta"],
        host_hss_file = config["PathSeq"]["host_bfi"],
        taxonomy_db = config["PathSeq"]["taxonomy_db"]
    params:
        host_bwa_image = basename(config["PathSeq"]["host_img"]),
        microbe_bwa_image = basename(config["PathSeq"]["microbe_bwa_image"]),
        microbe_fasta_file = basename(config["PathSeq"]["microbe_fasta"]),
        host_hss_file = basename(config["PathSeq"]["host_bfi"]),
        taxonomy_db = basename(config["PathSeq"]["taxonomy_db"])
    output:
        pathseq_bam = expand(join("output", "PathSeq", "{patient}-{sample}", "pathseq.bam"), zip, sample=samples["sample"], patient=samples["patient"]),
        pathseq_output = expand(join("output", "PathSeq", "{patient}-{sample}", "pathseq.txt"), zip, sample=samples["sample"], patient=samples["patient"])
    run:
        shell("mkdir /lscratch/$SLURM_JOBID/tmp")
        shell("cp /data/Robinson-SB/PathSeq-data/* /lscratch/$SLURM_JOBID")
        for bam_file, pathseq_bam, pathseq_output in zip(input.bam_file, output.pathseq_bam, output.pathseq_output):
            shell(
                "module load GATK/4.1.6.0 && "
                "gatk PathSeqPipelineSpark "
                "--input '{bam_file}' "
                "--filter-bwa-image /lscratch/$SLURM_JOBID/{params.host_bwa_image} "
                "--kmer-file /lscratch/$SLURM_JOBID/{params.host_hss_file} "
                "--microbe-fasta /lscratch/$SLURM_JOBID/{params.microbe_fasta_file} "
                "--microbe-bwa-image /lscratch/$SLURM_JOBID/{params.microbe_bwa_image} "
                "--taxonomy-file /lscratch/$SLURM_JOBID/{params.taxonomy_db} "
                "--output '{pathseq_bam}' "
                "--scores-output '{pathseq_output}' "
                '--java-options "-Xmx64g -Xms64G -Djava.io.tmpdir=/lscratch/$SLURM_JOBID/tmp -XX:+UseG1GC -XX:ParallelGCThreads=8 -XX:ConcGCThreads=2" '
                '--spark-master local[8]'
            )






rule convert_FASTQ_to_BAM:
    input:
        fq1=RAW_FASTQ1_FILE,
        fq2=RAW_FASTQ2_FILE
    output:
        config["PathSeq"]["bam_file"]
    shell:
        "module load picard && "
        "java -Xmx8g -XX:ParallelGCThreads=5 -jar $PICARDJARPATH/picard.jar "
        "FastqToSam F1={input.fq1} F2={input.fq2} O={output} "
        "SM={wildcards.sample} RG={wildcards.sample} "
        "TMP_DIR=/lscratch/$SLURM_JOBID"

rule move_and_rename_FASTQ_File:
    input:
        RAW_FASTQ1_FILE,
        RAW_FASTQ2_FILE
    output:
        temp(FASTQ1_FILE),
        temp(FASTQ2_FILE)
    shell:
        "cp {input[0]} {output[0]} && "
        "cp {input[1]} {output[1]}"
